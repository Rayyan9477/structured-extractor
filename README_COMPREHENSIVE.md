# Medical Superbill Data Extraction System

A comprehensive Python project designed to automate the extraction of structured data from medical superbills using advanced OCR and NLP models from Hugging Face.

## ğŸš€ Features

- **Multi-Model OCR Pipeline**: Supports handwritten and printed text using echo840/MonkeyOCR and nanonets/Nanonets-OCR-s
- **Intelligent Data Extraction**: Utilizes numind/NuExtract-2.0-4B for structured medical data extraction
- **Multi-Patient Document Handling**: Automatically detects and separates multiple patients within single documents
- **HIPAA-Compliant Processing**: Built-in PHI detection and anonymization capabilities
- **Comprehensive Validation**: CPT code, ICD-10 code, and medical data validation
- **Multiple Export Formats**: CSV, JSON, and Excel export with customizable formatting
- **Async Processing**: High-performance async/await architecture for batch processing
- **Configurable Pipeline**: YAML-based configuration for easy customization

## ğŸ“‹ Extracted Data Fields

- **Patient Information**: Names, DOB, Patient ID, Contact details
- **Medical Codes**: CPT codes, ICD-10 diagnosis codes with descriptions
- **Service Information**: Date of service, Provider details, NPI numbers
- **Financial Data**: Charges, payments, insurance information
- **PHI Detection**: Automatic identification of protected health information

## ğŸ—ï¸ Architecture

```
src/
â”œâ”€â”€ core/                    # Core configuration and data models
â”‚   â”œâ”€â”€ config_manager.py    # YAML configuration management
â”‚   â”œâ”€â”€ logger.py           # HIPAA-compliant logging
â”‚   â””â”€â”€ data_schema.py      # Pydantic data models
â”œâ”€â”€ processors/             # Document and OCR processing
â”‚   â”œâ”€â”€ document_processor.py  # PDF/image preprocessing
â”‚   â””â”€â”€ ocr_engine.py          # Multi-model OCR pipeline
â”œâ”€â”€ models/                 # Model management
â”‚   â””â”€â”€ model_manager.py    # Hugging Face model handling
â”œâ”€â”€ extractors/             # Data extraction engines
â”‚   â”œâ”€â”€ field_detector.py   # Regex-based field detection
â”‚   â”œâ”€â”€ nuextract_engine.py # NuExtract integration
â”‚   â””â”€â”€ multi_patient_handler.py # Multi-patient processing
â”œâ”€â”€ validators/             # Data validation
â”‚   â””â”€â”€ data_validator.py   # CPT/ICD-10/date validation
â”œâ”€â”€ exporters/              # Export functionality
â”‚   â””â”€â”€ data_exporter.py    # CSV/JSON/Excel export
â””â”€â”€ extraction_engine.py    # Main extraction pipeline
```

## ğŸš€ Quick Start

### Installation

1. **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd structured-extractor
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure the system** (optional):
   Edit `config/config.yaml` to customize settings.

### Basic Usage

```python
import asyncio
from src.extraction_engine import ExtractionEngine

async def extract_superbill():
    # Initialize the extraction engine
    engine = ExtractionEngine()
    
    # Extract data from a file
    results = await engine.extract_from_file("path/to/superbill.pdf")
    
    # Print results
    print(f"Found {results.total_patients} patients")
    for patient in results.patients:
        print(f"Patient: {patient.first_name} {patient.last_name}")
        print(f"CPT Codes: {[cpt.code for cpt in patient.cpt_codes]}")
        print(f"ICD-10 Codes: {[icd.code for icd in patient.icd10_codes]}")
    
    # Export to CSV
    engine.export_to_csv(results, "output/extracted_data.csv")

# Run the extraction
asyncio.run(extract_superbill())
```

### Text Extraction

```python
async def extract_from_text():
    engine = ExtractionEngine()
    
    text = """
    Patient: John Doe
    DOB: 01/15/1980
    CPT: 99213 - Office visit
    ICD-10: I10 - Essential hypertension
    """
    
    results = await engine.extract_from_text(text)
    return results
```

### Batch Processing

```python
async def batch_process():
    engine = ExtractionEngine()
    
    file_paths = ["file1.pdf", "file2.pdf", "file3.pdf"]
    results_list = await engine.extract_batch(file_paths)
    
    # Export all results
    for i, results in enumerate(results_list):
        engine.export_to_json(results, f"output/results_{i}.json")
```

## ğŸ§ª Testing

Run the example script to test the system:

```bash
python examples/usage_example.py
```

The script demonstrates:
- Basic file extraction
- Text-based extraction
- Data validation
- Multi-format export
- Batch processing
- PHI anonymization

## ğŸ“ Project Structure

```
structured-extractor/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml          # Main configuration file
â”œâ”€â”€ src/                     # Source code
â”‚   â”œâ”€â”€ core/               # Core components
â”‚   â”œâ”€â”€ processors/         # Document processing
â”‚   â”œâ”€â”€ models/             # Model management
â”‚   â”œâ”€â”€ extractors/         # Data extraction
â”‚   â”œâ”€â”€ validators/         # Data validation
â”‚   â”œâ”€â”€ exporters/          # Export functionality
â”‚   â””â”€â”€ extraction_engine.py # Main engine
â”œâ”€â”€ examples/               # Usage examples
â”‚   â”œâ”€â”€ usage_example.py    # Comprehensive example
â”‚   â””â”€â”€ sample_superbill.pdf # Sample file (add your own)
â”œâ”€â”€ docs/                   # Documentation
â”œâ”€â”€ tests/                  # Unit tests
â”œâ”€â”€ output/                 # Output directory
â”œâ”€â”€ requirements.txt        # Dependencies
â””â”€â”€ README.md              # This file
```

## ğŸ”§ System Requirements

- **Python**: 3.8+
- **Memory**: 8GB RAM minimum (16GB recommended for large batches)
- **Storage**: 5GB for models and dependencies
- **GPU**: Optional but recommended for faster processing

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Run the test suite
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **Hugging Face**: For providing the transformer models
- **echo840/MonkeyOCR**: Handwriting OCR model
- **numind/NuExtract-2.0-4B**: Structured data extraction model
- **nanonets/Nanonets-OCR-s**: Printed text OCR model

---

**Note**: This system is designed for research and development purposes. Ensure compliance with HIPAA and other healthcare regulations when processing real patient data.
